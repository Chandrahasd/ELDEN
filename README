README

Improving Entity Linking Performance of Sparsely Linked Entities And Knowledge Bases

This package contains the following four folders. Run the system in the given order.

A. Corpus :
1. Wikipedia (cleaned as specified in paper) = Titles3.csv, gensimWord2vecModel.csv
2. Web Corpus. = EDqueries.csv, evalEntitiesMap.txt, trainingEntities.py, processMultipleEntities.py, WebScraping.py

B. Dataset :
1. TAC2010 = TACforNED
2. CoNLL = https://github.com/masha-p/PPRforNED 

C. Preprocess:
1. Create entity co-location index. 
 $ python2.7 pmi_index.py base_co.npy/None vocab.pickle output_file file_scraped_from_web
2. Start PMI Server. 
 $ python pmi_service.py
3. Train entity embeddings. 
 th> main.lua <<word2vec.lua>>
4. Start Embedding Distance Servers. 
 th> EDServer.lua

D. Entity Linker:
1. Create train and test dataset
 $ py createTrainData.py
2. Run Entity Linker
 $ py classify.py

E. Evaluation :
1. Head entities versus tail entities statistics
 $ python TailEntities.py

